{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron and Logistics Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to read the file\n",
    "def read_file(filename):\n",
    "    temping = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            temp = list(map(float, line.split(' ')))\n",
    "            #temp = line.split(' ')\n",
    "            temping.append(temp)\n",
    "    return np.array(temping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(x):\n",
    "    temping = []\n",
    "    temping2 = []\n",
    "    for i in x:\n",
    "        temping.append(i[:-1])\n",
    "        temping2.append(i[-1])\n",
    "    return np.array(temping),np.array(temping2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the train set, test set, validation set.\n",
    "train_data = read_file('train_set.txt')\n",
    "test_data = read_file('test_set.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. write a linear classifier with perceptron that can predict if a post belongs to class 1 or\n",
    "class 2. For this purpose, your training data is the subset of train_set.txt that has label 1 or 2, and\n",
    "your test data is the subset of pa3test.txt that has label 1 or 2.\n",
    "Assume that data is linearly separable by a hyperplane through the origin. Run two, three and four\n",
    "passes of perceptron on the training dataset to find classifiers that separate the two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_12(data_set):\n",
    "    temp = data_set.copy().tolist()\n",
    "    tempx = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i][-1]==1 or temp[i][-1] == 2:\n",
    "            tempx.append(temp[i])\n",
    "    return np.array(tempx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label(y):\n",
    "    temp = y.copy()\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] == 2:\n",
    "            temp[i] = -1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_label(select_12(train_data))\n",
    "x_test, y_test= split_label(select_12(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train = change_label(y_train)\n",
    "new_y_test = change_label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_w(x_train, y_train,n):\n",
    "    the_w = np.array([0] * len(x_train[0]))\n",
    "    for _ in range(0,n):\n",
    "        for i in range(len(x_train)):\n",
    "            checker = y_train[i] * np.dot(the_w, x_train[i])\n",
    "            if checker <= 0:\n",
    "                the_w = the_w + x_train[i] * y_train[i]\n",
    "    return the_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row,weight):\n",
    "    activation = np.dot(row,weight)\n",
    "    if activation >=0:\n",
    "        return 1\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error(x_train,y_train,the_w):\n",
    "    prediction = []\n",
    "    for i in x_train:\n",
    "        prediction.append(predict(i,the_w))\n",
    "    prediction = np.array(prediction)\n",
    "    return 1-(sum(prediction == y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "for i in range(2,5):\n",
    "    the_w = update_w(x_train,new_y_train,i)\n",
    "    train_error.append(prediction_error(x_train,new_y_train,the_w))\n",
    "    test_error.append(prediction_error(x_test,new_y_test,the_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of perceptron</th>\n",
       "      <th>train_error</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>0.061008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # of perceptron  train_error  test_error\n",
       "0                2     0.035780    0.061008\n",
       "1                3     0.018349    0.045093\n",
       "2                4     0.016514    0.045093"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'# of perceptron':[2,3,4],'train_error':train_error,'test_error':test_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. training data is the subset of train_set.txt\n",
    "that has label 1 or 2, and your test data is the subset of test_set.txt that has label 1 or 2.\n",
    "Again, the classifier is a hyperplane through the origin. Starting with the initial point w0 set to the\n",
    "all zeros vector, run 10, 50 and 100 iterations of gradient descent on the following logistic regression\n",
    "loss function with learning rate η = 0.001:\n",
    "L(w) = Xn\n",
    "i=1\n",
    "log (1 + e\n",
    "−yiwT xi\n",
    "),\n",
    "where {xi\n",
    ", yi}\n",
    "n\n",
    "i=1 is the dataset, xi ∈ R\n",
    "d\n",
    ", yi ∈ {−1, 1} and w ∈ R\n",
    "d\n",
    "is the parameter vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_w_logistic(x_train, y_train,n):\n",
    "    the_w = np.array([0] * len(x_train[0]))\n",
    "    for _ in range(0,n):\n",
    "        temp = np.array([0] * len(x_train[0]))\n",
    "        # the loss function\n",
    "        for i in range(len(x_train)):\n",
    "            denom = np.exp(y_train[i] * np.dot(the_w, x_train[i]))+1\n",
    "            nom = y_train[i] * x_train[i]\n",
    "            loss_function = nom / denom \n",
    "            temp = temp + loss_function\n",
    "        the_w = the_w + 0.001 * temp\n",
    "    return the_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic(row,weight):\n",
    "    activation  = 1 / (1 + np.exp(np.dot(-weight,row)))\n",
    "    if activation > 0.5:\n",
    "        return 1\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = update_w_logistic(x_train,new_y_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error_logistic(x_train,y_train,the_w):\n",
    "    prediction = []\n",
    "    for i in x_train:\n",
    "        prediction.append(predict_logistic(i,the_w))\n",
    "    prediction = np.array(prediction)\n",
    "    return 1-(sum(prediction == y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4972477064220183"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_error_logistic(x_train,new_y_train,aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "number_iteration = [10,50,100]\n",
    "for i in number_iteration:\n",
    "    the_w = update_w_logistic(x_train,new_y_train,i)\n",
    "    train_error.append(prediction_error_logistic(x_train,new_y_train,the_w))\n",
    "    test_error.append(prediction_error_logistic(x_test,new_y_test,the_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_iteration</th>\n",
       "      <th>train_error</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.297248</td>\n",
       "      <td>0.297082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.039450</td>\n",
       "      <td>0.061008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.045093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_iteration  train_error  test_error\n",
       "0                10     0.297248    0.297082\n",
       "1                50     0.039450    0.061008\n",
       "2               100     0.020183    0.045093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'number_iteration':[10,50,100],'train_error':train_error,'test_error':test_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Consider the perceptron classifier w that you built by running three passes on the data. Now\n",
    "I try to interpret this classifier.\n",
    "Find the three coordinates in w with the highest and lowest values. What are the words (from\n",
    "dictionary.txt) that correspond to these coordinates? The three highest coordinates are those\n",
    "words whose presence indicates the positive class most strongly, and the three lowest coordinates are\n",
    "those words whose presence indicates the negative class most strongly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_dictionary(filename):\n",
    "    temping = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            temp =  line.split()\n",
    "            #temp = line.split(' ')\n",
    "            temping += temp\n",
    "    return np.array(temping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_array = read_file_dictionary('pa3dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_w = update_w(x_train,new_y_train,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['he', 'team', 'game'], dtype='<U12')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_array[the_w.argsort()[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['file', 'program', 'line'], dtype='<U12')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_array[the_w.argsort()[::-1][:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Repeat Part (3) of the question on the logistic regression classifier that you got after 50 iterations of\n",
    "gradient descent in part (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "the_w = update_w_logistic(x_train,new_y_train,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['he', 'game', 'they'], dtype='<U12')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_array[the_w.argsort()[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['window', 'file', 'use'], dtype='<U12')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_array[the_w.argsort()[::-1][:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. I will build a one-vs-all multi-class classifier with a Don’t Know option.\n",
    "For each class i = 1, . . . , 6, run a single pass of the perceptron algorithm on the training dataset to\n",
    "compute a linear classifier separating the training data points in class i from the training data points\n",
    "not in class i. Call this classifier Ci\n",
    ". I will now use these classifiers to construct a one-vs-all multiclass\n",
    "classifier.\n",
    "Given a test example x, the one-vs-all classifier predicts as follows. If Ci(x) = i for exactly one\n",
    "i = 1, . . . , 6, then predict label i. If Ci(x) = i for more than one i in 1, . . . , 6, or if Ci(x) = i for no i,\n",
    "then report Don’t Know.\n",
    "I will build a confusion matrix, that indicates how well a multiclass classifier can distinguish between\n",
    "classes. Recall from lecture that a confusion matrix is a 6×6 matrix, where each row is labelled 1, . . . , 6\n",
    "and each column is labelled 1, . . . , 6. The entry of the matrix at row i and column j is Cij/Nj where\n",
    "Cij is the number of test examples that have label j but are classified as label i by the classifier, and\n",
    "Nj is the number of test examples that have label j. Since the one-vs-all classifier can also predict\n",
    "Don’t Know, the confusion matrix will now be an 7 × 6 matrix – that is, it will have an extra row\n",
    "corresponding to the Don’t Know predictions.\n",
    "Write down the confusion matrix for the one-vs-all classifier on the training data in pa3train.txt\n",
    "based on the test data in pa3test.txt.\n",
    "Looking at the confusion matrix, what are the i and j in the following statements?\n",
    "(a) The perceptron classifier has the highest accuracy for examples that belong to class i.\n",
    "(b) The perceptron classifier has the least accuracy for examples that belong to class i.\n",
    "(c) The perceptron classifier most often mistakenly classifies an example in class j as belonging to\n",
    "class i, for i, j ∈ {1, 2, 3, 4, 5, 6} (i.e., excluding Don’t Know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_label(train_data)\n",
    "x_test, y_test= split_label(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_muti(y,class1):\n",
    "    temp = y.copy()\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] == class1:\n",
    "            temp[i] = 1\n",
    "        else:\n",
    "            temp[i] = -1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error_q5(x_train,y_train,the_w):\n",
    "    prediction = []\n",
    "    for i in x_train:\n",
    "        prediction.append(predict(i,the_w))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for i in range(1,7):\n",
    "    new_y_train = change_label_muti(y_train,i)\n",
    "    new_y_test = change_label_muti(y_test,i)\n",
    "    the_w = update_w(x_train,new_y_train,1)\n",
    "    total.append(prediction_error_q5(x_test,new_y_test,the_w))\n",
    "total = np.array(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_vs_all = []\n",
    "for i in range(len(total[0])):\n",
    "    if np.count_nonzero(total[:,i] ==1) ==1:\n",
    "        one_vs_all.append((np.where(total[:,i] == 1)[0][0])+1)\n",
    "    else:\n",
    "        one_vs_all.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros(shape = (7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(one_vs_all)):\n",
    "    if one_vs_all[i] == y_test[i]:\n",
    "        value = int(one_vs_all[i])\n",
    "        confusion_matrix[value - 1][value - 1] += 1\n",
    "    if one_vs_all[i] != y_test[i] and one_vs_all[i] != -1 :\n",
    "        valuei = int(y_test[i])\n",
    "        valuej = int(one_vs_all[i])\n",
    "        confusion_matrix[valuej - 1][valuei - 1] += 1\n",
    "    if one_vs_all[i] == -1:\n",
    "        valuei = int(y_test[i])\n",
    "        valuej = one_vs_all[i]\n",
    "        confusion_matrix[6][valuei-1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133.,   2.,   6.,   4.,   0.,   0.],\n",
       "       [  2., 126.,   6.,   5.,   2.,   2.],\n",
       "       [  0.,   3.,  65.,   0.,   0.,   3.],\n",
       "       [  3.,   1.,   0., 126.,   0.,   0.],\n",
       "       [  3.,   6.,  13.,   1., 125.,  13.],\n",
       "       [  1.,   2.,   6.,   0.,  11.,  54.],\n",
       "       [ 43.,  52.,  79.,  48.,  18.,  36.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont know</th>\n",
       "      <td>43.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1      2     3      4      5     6\n",
       "1          133.0    2.0   6.0    4.0    0.0   0.0\n",
       "2            2.0  126.0   6.0    5.0    2.0   2.0\n",
       "3            0.0    3.0  65.0    0.0    0.0   3.0\n",
       "4            3.0    1.0   0.0  126.0    0.0   0.0\n",
       "5            3.0    6.0  13.0    1.0  125.0  13.0\n",
       "6            1.0    2.0   6.0    0.0   11.0  54.0\n",
       "dont know   43.0   52.0  79.0   48.0   18.0  36.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=confusion_matrix, index=[\"1\", \"2\",\"3\", \"4\",\"5\", \"6\",\"dont know\"], columns=[\"1\", \"2\",\"3\", \"4\",\"5\", \"6\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718919</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.120370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont know</th>\n",
       "      <td>0.232432</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6\n",
       "1          0.718919  0.010417  0.034286  0.021739  0.000000  0.000000\n",
       "2          0.010811  0.656250  0.034286  0.027174  0.012821  0.018519\n",
       "3          0.000000  0.015625  0.371429  0.000000  0.000000  0.027778\n",
       "4          0.016216  0.005208  0.000000  0.684783  0.000000  0.000000\n",
       "5          0.016216  0.031250  0.074286  0.005435  0.801282  0.120370\n",
       "6          0.005405  0.010417  0.034286  0.000000  0.070513  0.500000\n",
       "dont know  0.232432  0.270833  0.451429  0.260870  0.115385  0.333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df / df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The perceptron classifier has the highest accuracy for examples that belong to class 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The perceptron classifier has the least accuracy for examples that belong to class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)The perceptron classifier most often mistakenly classifies an example in class 6 as class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
